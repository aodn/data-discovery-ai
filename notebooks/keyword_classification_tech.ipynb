{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A ML model for Keyword Classification Task: Technical Notebook\n",
        "This notebook introduces how we define, design, and development of a ML model for Keyword Classification Task, from a technical perspective.### Preliminaries\n",
        "The AODN catalogue $C=\\{M, K, P\\}$ serves as a platform for storing datasets and their associated metadata. $M=\\{m_1,m_2,\\ldots, m_x\\}$ is a set of metadata records which are used to describe the dataset in AODN catalogue $C$. $K=\\{k_1, k_2, \\ldots, k_y\\}$ is a set of pre-defined keywords that are used to categorise dataset. $P=\\{p_1, p_2, \\ldots, p_n\\}$ is a set of pre-defined parameters used to describe the attributes of raw data.\n",
        "\n",
        "- **Definition 1: A metadata $m_i=(d_i, K_i, P_i), m_i \\in M$** is a record describing a dataset. Specifically, $i$ is the unique identifier of the record. $d_i$ is a textual abstract that serves as the description of the dataset. $K_i \\subseteq K$ is a subset of keywords used to label the dataset. $P_i \\subseteq P$ is a subset of parameters used to describe the attributes of the raw data in the dataset.\n",
        "\n",
        "- **Definition 2: A description $d_i$** is the textual abstract of a metadata, which is used to describe the dataset in a plain text way. $\\mathbf{d_i}$ is the embedding representation of the textual description $d_i$. We used ``BERT'' to calculate the description embedding $\\mathbf{d_i}$ for each description $d_i$.\n",
        "\n",
        "- **Definition 3: A keyword matrix $\\mathbf{K}$** is a pre-defined textual label, which is be used to categorise datasets.$X \\times Y$ binary matrix, where $X=|M|$ is the size of the metadata records set $M=\\{m_1,m_2,\\ldots, m_x\\}$, and $Y=|K|$ is the size of the keywords set $K=\\{k_1, k_2, \\ldots, k_y\\}$. Each entry $ \\mathbf{K}[i, j] $ is 1 if metadata record $ m_i $ is associated with keyword $ k_j $, and 0 otherwise.\n",
        "### Problem Description\n",
        "In the catalogue $C = \\{M, K, P\\}$, a subset of metadata records, $M_t \\subseteq M$, have not yet been categorised with keywords. For these records, $K_i = \\emptyset $ for all $m_i \\in M_t$. Given another subset of metadata records, $M_s \\subseteq M$, where each record has already been categorised with keywords (i.e., $K_i \\neq \\emptyset $ for all $m_i \\in M_s$). The research question is as follows:\n",
        "\n",
        "How to design and develop a machine learning model, denoted as $MM_{keywords}$, that can automatically label the uncategorised metadata records $M_t$ using a predefined set of keywords $K$. Specifically, the model should be trained to learn a mapping rule $d_i \\mapsto K_i$ based on the observed patterns from the labelled metadata records $M_s$, where each description $d_i$ of a metadata record $m_i \\in M_s$ is associated with a set of keywords $K_i$. Once trained, the model should be able to apply this learned mapping to accurately categorise the records in $M_t$ by assigning their corresponding keywords based on the records' descriptions.\n",
        "\n",
        "To simplify the task, we restrict the scope of keywords to those falling within the primary AODN vocabularies:\n",
        "\n",
        "- AODN Organisation Vocabulary\n",
        "- AODN Instrument Vocabulary\n",
        "- AODN Discovery Parameter Vocabulary\n",
        "- AODN Platform Vocabulary\n",
        "- AODN Parameter Category Vocabulary\n",
        "\n",
        "Only keywords $k_j \\in K_i$ that are part of the listed AODN vocabularies will be considered. Any keyword not belonging to these vocabularies will be excluded from $K_i$ for all metadata records in the categorised metadata set $M_s$.\n",
        "\n",
        "## Connecting Datasets\n",
        "The metadata records are fetched by querying ElasticSearch with the following code:\n",
        "```json\n",
        "POST /es-indexer-edge/_search\n",
        "    {\n",
        "    \"size\": 11000,\n",
        "    \"query\": {\n",
        "        \"match_all\": {}\n",
        "    }\n",
        "    }\n",
        "```\n",
        "Programmatically, we can fetch the data by connecting to ElasticSearch.\n",
        "\n",
        "TODO: add script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Identify Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9856 entries, 0 to 9855\n",
            "Data columns (total 40 columns):\n",
            " #   Column                                               Non-Null Count  Dtype \n",
            "---  ------                                               --------------  ----- \n",
            " 0   _index                                               9856 non-null   object\n",
            " 1   _id                                                  9856 non-null   object\n",
            " 2   _score                                               9856 non-null   int64 \n",
            " 3   _ignored                                             5600 non-null   object\n",
            " 4   _source.title                                        9856 non-null   object\n",
            " 5   _source.description                                  9856 non-null   object\n",
            " 6   _source.extent.bbox                                  9856 non-null   object\n",
            " 7   _source.extent.temporal                              9856 non-null   object\n",
            " 8   _source.summaries.score                              9856 non-null   int64 \n",
            " 9   _source.summaries.status                             9646 non-null   object\n",
            " 10  _source.summaries.credits                            9856 non-null   object\n",
            " 11  _source.summaries.scope.code                         6338 non-null   object\n",
            " 12  _source.summaries.scope.name                         854 non-null    object\n",
            " 13  _source.summaries.statement                          8454 non-null   object\n",
            " 14  _source.summaries.creation                           5549 non-null   object\n",
            " 15  _source.summaries.revision                           8080 non-null   object\n",
            " 16  _source.summaries.dataset_group                      9374 non-null   object\n",
            " 17  _source.summaries.update_frequency                   9856 non-null   object\n",
            " 18  _source.summaries.temporal                           9856 non-null   object\n",
            " 19  _source.summaries.parameter_vocabs                   3552 non-null   object\n",
            " 20  _source.contacts                                     9856 non-null   object\n",
            " 21  _source.languages                                    9856 non-null   object\n",
            " 22  _source.links                                        9856 non-null   object\n",
            " 23  _source.license                                      8644 non-null   object\n",
            " 24  _source.providers                                    9856 non-null   object\n",
            " 25  _source.themes                                       9856 non-null   object\n",
            " 26  _source.id                                           9856 non-null   object\n",
            " 27  _source.search_suggestions.abstract_phrases          9856 non-null   object\n",
            " 28  _source.search_suggestions.parameter_vocabs_sayt     3552 non-null   object\n",
            " 29  _source.sci:citation                                 9856 non-null   object\n",
            " 30  _source.type                                         9856 non-null   object\n",
            " 31  _source.stac_version                                 9856 non-null   object\n",
            " 32  _source.stac_extensions                              9856 non-null   object\n",
            " 33  _source.summaries.proj:geometry.geometries           9114 non-null   object\n",
            " 34  _source.summaries.proj:geometry.type                 9114 non-null   object\n",
            " 35  _source.summaries.platform_vocabs                    2540 non-null   object\n",
            " 36  _source.search_suggestions.platform_vocabs_sayt      2540 non-null   object\n",
            " 37  _source.summaries.dataset_provider                   739 non-null    object\n",
            " 38  _source.summaries.organisation_vocabs                141 non-null    object\n",
            " 39  _source.search_suggestions.organisation_vocabs_sayt  141 non-null    object\n",
            "dtypes: int64(2), object(38)\n",
            "memory usage: 3.0+ MB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "ds = pd.read_csv(\"output/AODN.tsv\", sep=\"\\t\")\n",
        "ds.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(200, 4)\n"
          ]
        }
      ],
      "source": [
        "from utils.preprocessor import identify_sample\n",
        "\n",
        "vocabs = ['AODN Organisation Vocabulary']\n",
        "\n",
        "sampleDS = identify_sample(ds=ds, vocabs=vocabs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from utils.preprocessor import calculate_embedding\n",
        "# sampleDS = calculate_embedding(sampleDS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.preprocessor import load_from_file, save_to_file\n",
        "dataset = load_from_file('./output/AODN.pkl')\n",
        "dataset.columns = ['id', 'title', 'description', 'embedding']\n",
        "\n",
        "keywordDS = pd.read_csv('./output/keywords_sample.tsv', sep='\\t')\n",
        "keywordDS = keywordDS.merge(dataset, on=['id', 'title', 'description'])\n",
        "save_to_file(keywordDS, './output/keywords_sample.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.preprocessor import save_to_file\n",
        "save_to_file(sampleDS, './output/keywords_sample.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.preprocessor import load_from_file\n",
        "sampleDS = load_from_file('./output/keywords_sample.pkl')\n",
        "sampleDS.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5       [{'concepts': [{'id': 'Oceans | Ocean Temperat...\n",
              "9       [{'concepts': [{'id': 'Oceans | Ocean Circulat...\n",
              "169     [{'concepts': [{'id': 'diver'}], 'scheme': 'di...\n",
              "219     [{'concepts': [{'id': 'Oceans | Ocean Circulat...\n",
              "262     [{'concepts': [{'id': 'Oceans | Ocean Temperat...\n",
              "                              ...                        \n",
              "9617    [{'concepts': [{'id': 'Oceans | Ocean Temperat...\n",
              "9643    [{'concepts': [{'id': 'Oceans | Ocean Optics |...\n",
              "9667    [{'concepts': [{'id': 'Southern Ocean Time Ser...\n",
              "9755    [{'concepts': [{'id': 'Oceans | Ocean Chemistr...\n",
              "9830    [{'concepts': [{'id': 'Oceans | Ocean Temperat...\n",
              "Name: keywords, Length: 200, dtype: object"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampleDS['keywords']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.preprocessor import extract_labels"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
