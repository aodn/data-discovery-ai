{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML model for Keyword Classification\n",
        "This notebook introduces (1) how we prepare and preprocess the datasets; (2) how we train and evaluate the ML model; and (3) how we use this trained ML model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Prepare Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Query result from ElasticSearch with the following scripts, make sure the number of the size is larger than the real number of records so that can get all records.\n",
        "```\n",
        "    POST /es-indexer-edge/_search\n",
        "    {\n",
        "    \"size\": 11000,\n",
        "    \"query\": {\n",
        "        \"match_all\": {}\n",
        "    }\n",
        "    }\n",
        "```\n",
        "and to get the IMOS records only:\n",
        "```\n",
        "    POST /es-indexer-edge/_search\n",
        "    {\n",
        "    \"size\": 800,\n",
        "    \"query\": {\n",
        "        \"bool\": {\n",
        "        \"must\": [\n",
        "            {\n",
        "            \"match\": {\n",
        "                \"providers.name\": \"IMOS\"\n",
        "            }\n",
        "            }\n",
        "        ]\n",
        "        }\n",
        "    }\n",
        "    }\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 1: import necessory libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\yhu12\\AppData\\Local\\miniforge3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, hamming_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import pandas as pd\n",
        "import ast\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "import logging\n",
        "from matplotlib import pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "import os\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] =\"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 2: Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASET = \"./output/AODN_description.tsv\"\n",
        "KEYWORDS_DS = \"./output/AODN_parameter_vocabs.tsv\"\n",
        "TARGET_DS = \"./output/keywords_target.tsv\"\n",
        "VOCABS = ['AODN Discovery Parameter Vocabulary']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DATASET is a subset of the original source dataset, containing only the '_id', '_source.title', and '_source.description' columns. We retained these columns because we want to use '_source.description' as the feature X for the classification task. Therefore, we calculated the embeddings of the descriptions. Finally, we saved the processed dataset as a file for future use, as calculating embeddings is time-consuming, and saving/loading the file helps reduce this time overhead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9856 entries, 0 to 9855\n",
            "Data columns (total 3 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   _id                  9856 non-null   object\n",
            " 1   _source.title        9856 non-null   object\n",
            " 2   _source.description  9856 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 231.1+ KB\n"
          ]
        }
      ],
      "source": [
        "ds = pd.read_csv(DATASET, sep='\\t')\n",
        "ds.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1588</td>\n",
              "      <td>1588</td>\n",
              "      <td>1588</td>\n",
              "      <td>1588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>1588</td>\n",
              "      <td>1581</td>\n",
              "      <td>1343</td>\n",
              "      <td>457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>52b58d9a-a0b4-4396-be8e-a9e5e2b493f0</td>\n",
              "      <td>IMOS SOOP Underway Data from AIMS Vessel RV So...</td>\n",
              "      <td>'Australian National Moorings Network' (ANMN) ...</td>\n",
              "      <td>[{'concepts': [{'id': 'Practical salinity of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>44</td>\n",
              "      <td>463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          id   \n",
              "count                                   1588  \\\n",
              "unique                                  1588   \n",
              "top     52b58d9a-a0b4-4396-be8e-a9e5e2b493f0   \n",
              "freq                                       1   \n",
              "\n",
              "                                                    title   \n",
              "count                                                1588  \\\n",
              "unique                                               1581   \n",
              "top     IMOS SOOP Underway Data from AIMS Vessel RV So...   \n",
              "freq                                                    2   \n",
              "\n",
              "                                              description   \n",
              "count                                                1588  \\\n",
              "unique                                               1343   \n",
              "top     'Australian National Moorings Network' (ANMN) ...   \n",
              "freq                                                   44   \n",
              "\n",
              "                                                 keywords  \n",
              "count                                                1588  \n",
              "unique                                                457  \n",
              "top     [{'concepts': [{'id': 'Practical salinity of t...  \n",
              "freq                                                  463  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds = pd.read_csv(KEYWORDS_DS, sep='\\t')\n",
        "ds.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds = pd.read_csv(DATASET, sep='\\t')\n",
        "ds.describe()\n",
        "\n",
        "def get_description_embedding(text, tokenizer, model):\n",
        "    inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :] \n",
        "    return cls_embedding.squeeze().numpy()\n",
        "\n",
        "def calculate_embedding(ds):\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', clean_up_tokenization_spaces=False)\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "    tqdm.pandas()\n",
        "    ds['embedding'] = ds['_source.description'].progress_apply(lambda x: get_description_embedding(x, tokenizer, model))\n",
        "    return ds\n",
        "\n",
        "# saved_ds = calculate_embedding(ds)\n",
        "# save_to_file(ds, './output/AODN.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 3: Prepare Target set\n",
        "\n",
        "The target set is the metadata records that we want to apply our trained ML model for predicting keywords, this is all non-categorised records. We apply the calculated embeddings for these records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of                                         id   \n",
            "0     52bd4235-7461-47eb-a607-11cdbf93cd9f  \\\n",
            "1     52e8f4a0-4000-4650-9372-fd97de9e7725   \n",
            "2     531cc7a0-6548-485d-b3b2-d49b89e04a40   \n",
            "3     5335dd35-0a9a-453f-a1a9-95677f75bd8b   \n",
            "4     53556c47-38bb-4073-b67f-576e4e3c1903   \n",
            "...                                    ...   \n",
            "1070  fe70b360-2208-4a9b-8de6-bbd9c7f652bb   \n",
            "1071  ff34b8fc-8a52-4270-82b3-f6bebde4aa10   \n",
            "1072  fd2d6481-cc16-42af-af76-92ad0cdc166c   \n",
            "1073  fd4c6c5b-99da-4e77-adf5-ac04f54af393   \n",
            "1074  fffbf4b5-e860-407e-a4d8-6d81f93157fb   \n",
            "\n",
            "                                                  title   \n",
            "0     Corals and coral communities of Lord Howe Isla...  \\\n",
            "1     Predictive toxinology: calculated molecular de...   \n",
            "2     Benthic processes in the intertidal mudflats o...   \n",
            "3     Rapid Ecological Assessment (REA) of fringing ...   \n",
            "4     Impacts of individual aromatics on larvae of t...   \n",
            "...                                                 ...   \n",
            "1070  Towed Video deployments to address strategic k...   \n",
            "1071  Cross shelf distribution of copepods and fish ...   \n",
            "1072  Measurement of filtering rates of the salp, Th...   \n",
            "1073  High spatio-temporal variability in Acroporida...   \n",
            "1074  Hydrodynamics at the whole of Great Barrier Re...   \n",
            "\n",
            "                                            description  keywords   \n",
            "0     Ecological and taxonomic surveys of hermatypic...       NaN  \\\n",
            "1     Saxitoxins (STXs) were used to ascertain wheth...       NaN   \n",
            "2     Three types of mudbanks were studied: a physic...       NaN   \n",
            "3     A rapid assessment technique was chosen to sur...       NaN   \n",
            "4     This collection consists of a series of data s...       NaN   \n",
            "...                                                 ...       ...   \n",
            "1070  Towed video surveys between were carried out i...       NaN   \n",
            "1071  Zooplankton samples were collected during dayl...       NaN   \n",
            "1072  Measurements of the feeding rates of a salp, T...       NaN   \n",
            "1073  Datasets and R-scripts used to test for relati...       NaN   \n",
            "1074  A three-dimensional whole-of-GBR baroclinic hy...       NaN   \n",
            "\n",
            "                                              embedding  \n",
            "0     [-0.78608847, -0.2646339, -0.67208326, -0.0526...  \n",
            "1     [-1.025701, -0.4644198, -0.86336803, -0.016942...  \n",
            "2     [-0.65148205, -0.38566494, -0.3755086, 0.04004...  \n",
            "3     [-0.6867135, -0.48535475, -0.07764405, -0.1775...  \n",
            "4     [-0.67522246, -0.52606964, -0.3555009, -0.2979...  \n",
            "...                                                 ...  \n",
            "1070  [-0.79667413, -0.35468674, -0.14974017, -0.149...  \n",
            "1071  [-0.67965376, -0.7883273, -0.28499323, 0.16756...  \n",
            "1072  [-0.78284883, -0.41078278, -0.20454705, 0.0093...  \n",
            "1073  [-0.58545536, -0.3274092, 0.10505861, 0.199924...  \n",
            "1074  [-0.88062555, -0.6848005, -0.036394823, -0.097...  \n",
            "\n",
            "[1075 rows x 5 columns]>\n"
          ]
        }
      ],
      "source": [
        "from utils.preprocessor import load_from_file, save_to_file\n",
        "def get_target_ds():\n",
        "    target = pd.read_csv(TARGET_DS, sep='\\t')\n",
        "    aodn = load_from_file('./output/AODN.pkl')\n",
        "    aodn.columns = ['id', 'title', 'description', 'embedding']\n",
        "    merged_df = target.merge(aodn, on=['id', 'title','description'], how='left')\n",
        "    return merged_df\n",
        "\n",
        "target = get_target_ds()\n",
        "print(target.head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can check the keywords for the target dataset are all empty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_nan = target['keywords'].isnull().all()\n",
        "all_nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 4: Prepare train and test sets\n",
        "\n",
        "We prepare the train and test sets from the KEYWORDS_DS, which is the subset of AODN dataset that keywords using AODN vocabularies. We can check the keywords for the target dataset are all not empty."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keyword_ds = pd.read_csv(KEYWORDS_DS, sep='\\t')\n",
        "all_not_nan = keyword_ds['keywords'].notnull().all()\n",
        "all_not_nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1588</td>\n",
              "      <td>1588</td>\n",
              "      <td>1588</td>\n",
              "      <td>1588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>1588</td>\n",
              "      <td>1581</td>\n",
              "      <td>1343</td>\n",
              "      <td>457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>52b58d9a-a0b4-4396-be8e-a9e5e2b493f0</td>\n",
              "      <td>IMOS SOOP Underway Data from AIMS Vessel RV So...</td>\n",
              "      <td>'Australian National Moorings Network' (ANMN) ...</td>\n",
              "      <td>[{'concepts': [{'id': 'Practical salinity of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>44</td>\n",
              "      <td>463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          id   \n",
              "count                                   1588  \\\n",
              "unique                                  1588   \n",
              "top     52b58d9a-a0b4-4396-be8e-a9e5e2b493f0   \n",
              "freq                                       1   \n",
              "\n",
              "                                                    title   \n",
              "count                                                1588  \\\n",
              "unique                                               1581   \n",
              "top     IMOS SOOP Underway Data from AIMS Vessel RV So...   \n",
              "freq                                                    2   \n",
              "\n",
              "                                              description   \n",
              "count                                                1588  \\\n",
              "unique                                               1343   \n",
              "top     'Australian National Moorings Network' (ANMN) ...   \n",
              "freq                                                   44   \n",
              "\n",
              "                                                 keywords  \n",
              "count                                                1588  \n",
              "unique                                                457  \n",
              "top     [{'concepts': [{'id': 'Practical salinity of t...  \n",
              "freq                                                  463  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keyword_ds.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                         id   \n",
              "0     52b58d9a-a0b4-4396-be8e-a9e5e2b493f0  \\\n",
              "1     52c92036-cea9-4b1a-b4f0-cc94b8b5df98   \n",
              "2     52e8e882-5108-4295-b336-e97c11af7ad4   \n",
              "3     52f09a23-63a2-4c14-8b3b-1fc7c8167281   \n",
              "4     533bba87-bd26-4bb6-91a4-613d104ae310   \n",
              "...                                    ...   \n",
              "1583  ff50ae2f-0f79-4eaa-806c-8954ab0e545b   \n",
              "1584  fed52ea8-bde9-4126-aa3d-69431fce5694   \n",
              "1585  fcd7a039-2134-4761-ad08-ec42b8e05610   \n",
              "1586  fbe4dbce-3435-48df-a054-f0e399886e2b   \n",
              "1587  fe669c1d-6b14-467e-8d8e-f1bf192841aa   \n",
              "\n",
              "                                                  title   \n",
              "0     IMOS SOOP Underway Data from AIMS Vessel RV So...  \\\n",
              "1     IMOS - SRS - SST - L3C - NOAA 19 - 3 day - day...   \n",
              "2     Sea Water Temperature Logger Data at Taure Ree...   \n",
              "3     IMOS - ACORN - Turquoise Coast HF ocean radar ...   \n",
              "4            Square Rocks Air Pressure From 19 Dec 2009   \n",
              "...                                                 ...   \n",
              "1583  One Tree Island Air Pressure From 18 Nov 2008 ...   \n",
              "1584  Port Curtis Integrated Monitoring Program - PC...   \n",
              "1585  IMOS SOOP Underway Data from AIMS Vessel RV So...   \n",
              "1586  IMOS - SRS - SST - L3S - Single Sensor - 14 da...   \n",
              "1587    Masig Island Water Temperature From 26 Jul 2013   \n",
              "\n",
              "                                            description   \n",
              "0     'Ships of Opportunity' (SOOP) is a facility of...  \\\n",
              "1     This is a single sensor, multiple swath SSTski...   \n",
              "2     This data set was collected by one or more tem...   \n",
              "3     The Turquoise Coast (TURQ) HF ocean radar syst...   \n",
              "4     This data set was collected by weather sensors...   \n",
              "...                                                 ...   \n",
              "1583  The 'Wireless Sensor Networks Facility' (forme...   \n",
              "1584  This data set was collected by sensors deploye...   \n",
              "1585  'Ships of Opportunity' (SOOP) is a facility of...   \n",
              "1586  This is a multi-sensor SSTskin product for fou...   \n",
              "1587  This data set was collected by weather sensors...   \n",
              "\n",
              "                                               keywords  \n",
              "0     [{'concepts': [{'id': 'Practical salinity of t...  \n",
              "1     [{'concepts': [{'id': 'Oceans | Ocean Temperat...  \n",
              "2     [{'concepts': [{'id': 'Temperature of the wate...  \n",
              "3     [{'concepts': [{'id': 'Oceans | Ocean Circulat...  \n",
              "4     [{'concepts': [{'id': 'Pressure (measured vari...  \n",
              "...                                                 ...  \n",
              "1583  [{'concepts': [{'id': 'Pressure (measured vari...  \n",
              "1584  [{'concepts': [{'id': 'Oxygen Reduction Potent...  \n",
              "1585  [{'concepts': [{'id': 'Practical salinity of t...  \n",
              "1586  [{'concepts': [{'id': 'Oceans | Ocean Temperat...  \n",
              "1587  [{'concepts': [{'id': 'Temperature of the wate...  \n",
              "\n",
              "[1588 rows x 4 columns]>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keyword_ds.head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We format the keywords field for better read."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['AODN Discovery Parameter Vocabulary:Practical salinity of the water body', 'AODN Discovery Parameter Vocabulary:Fluorescence of the water body', 'AODN Discovery Parameter Vocabulary:Temperature of the water body', 'AODN Discovery Parameter Vocabulary:Turbidity of the water body']\n"
          ]
        }
      ],
      "source": [
        "def keywords_formatter(text):\n",
        "    keywords = ast.literal_eval(text)\n",
        "    k_list = []\n",
        "    for keyword in keywords:\n",
        "        for concept in keyword['concepts']:\n",
        "            if keyword['title'] in VOCABS:\n",
        "                concept_str = keyword['title'] + ':' + concept['id']\n",
        "                k_list.append(concept_str)\n",
        "    return k_list\n",
        "\n",
        "def extract_labels(ds):\n",
        "    ds['keywords'] = ds['keywords'].apply(lambda x: keywords_formatter(x))\n",
        "    return ds\n",
        "\n",
        "formatted_keywords_ds = extract_labels(keyword_ds)\n",
        "print(formatted_keywords_ds['keywords'].iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And apply embedding column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "aodn = load_from_file('./output/AODN.pkl')\n",
        "aodn.columns = ['id', 'title', 'description', 'embedding']\n",
        "X_df = formatted_keywords_ds.merge(aodn, on=['id', 'title','description'], how='left')\n",
        "\n",
        "# save for further use\n",
        "save_to_file(X_df, './output/keyword_train.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1588</td>\n",
              "      <td>1588</td>\n",
              "      <td>1588</td>\n",
              "      <td>1588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>1588</td>\n",
              "      <td>1581</td>\n",
              "      <td>1343</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>52b58d9a-a0b4-4396-be8e-a9e5e2b493f0</td>\n",
              "      <td>IMOS SOOP Underway Data from AIMS Vessel RV So...</td>\n",
              "      <td>'Australian National Moorings Network' (ANMN) ...</td>\n",
              "      <td>[AODN Discovery Parameter Vocabulary:Practical...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>44</td>\n",
              "      <td>463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          id   \n",
              "count                                   1588  \\\n",
              "unique                                  1588   \n",
              "top     52b58d9a-a0b4-4396-be8e-a9e5e2b493f0   \n",
              "freq                                       1   \n",
              "\n",
              "                                                    title   \n",
              "count                                                1588  \\\n",
              "unique                                               1581   \n",
              "top     IMOS SOOP Underway Data from AIMS Vessel RV So...   \n",
              "freq                                                    2   \n",
              "\n",
              "                                              description   \n",
              "count                                                1588  \\\n",
              "unique                                               1343   \n",
              "top     'Australian National Moorings Network' (ANMN) ...   \n",
              "freq                                                   44   \n",
              "\n",
              "                                                 keywords  \n",
              "count                                                1588  \n",
              "unique                                                237  \n",
              "top     [AODN Discovery Parameter Vocabulary:Practical...  \n",
              "freq                                                  463  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "formatted_keywords_ds.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We only want the keywords field as the output Y. So we transfer the values in keywords from a list to a binary matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlb = MultiLabelBinarizer()\n",
        "Y = mlb.fit_transform(formatted_keywords_ds['keywords'])\n",
        "Y_df = pd.DataFrame(Y, columns=mlb.classes_)\n",
        "save_to_file(Y_df, './output/AODN_vocabs_label.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:Abundance of biota</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:Accelerometer data</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:Acoustic signal return amplitude from the water body</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:Aluminium Bioaccumulation</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:Aluminium Dissolved Water Quality</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:Aluminium Total Water Quality</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:Ammonia-N Physicochemistry</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:Amplicon</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:Animal-borne video</th>\n",
              "      <th>...</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:net_downward_shortwave_flux_in_air</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:pH</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:pH (total scale) of the water body</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:particulate iron data quality flag</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:potential temperature</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:surface_albedo</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:the maximum potential quantum efficiency of Photosystem II</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:upwelling_longwave_flux_in_air</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:upwelling_shortwave_flux_in_air</th>\n",
              "      <th>AODN Discovery Parameter Vocabulary:voltage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "      <td>1588.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.001889</td>\n",
              "      <td>0.090680</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>0.002519</td>\n",
              "      <td>0.020151</td>\n",
              "      <td>0.010076</td>\n",
              "      <td>0.010705</td>\n",
              "      <td>0.020151</td>\n",
              "      <td>0.001889</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001259</td>\n",
              "      <td>0.010076</td>\n",
              "      <td>0.006927</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>0.001259</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>0.001259</td>\n",
              "      <td>0.001259</td>\n",
              "      <td>0.000630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.043437</td>\n",
              "      <td>0.287244</td>\n",
              "      <td>0.025094</td>\n",
              "      <td>0.050141</td>\n",
              "      <td>0.140561</td>\n",
              "      <td>0.099902</td>\n",
              "      <td>0.102943</td>\n",
              "      <td>0.140561</td>\n",
              "      <td>0.043437</td>\n",
              "      <td>0.025094</td>\n",
              "      <td>...</td>\n",
              "      <td>0.035477</td>\n",
              "      <td>0.099902</td>\n",
              "      <td>0.082966</td>\n",
              "      <td>0.025094</td>\n",
              "      <td>0.025094</td>\n",
              "      <td>0.035477</td>\n",
              "      <td>0.025094</td>\n",
              "      <td>0.035477</td>\n",
              "      <td>0.035477</td>\n",
              "      <td>0.025094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows \u00d7 393 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       AODN Discovery Parameter Vocabulary:   \n",
              "count                           1588.000000  \\\n",
              "mean                               0.001889   \n",
              "std                                0.043437   \n",
              "min                                0.000000   \n",
              "25%                                0.000000   \n",
              "50%                                0.000000   \n",
              "75%                                0.000000   \n",
              "max                                1.000000   \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:Abundance of biota   \n",
              "count                                        1588.000000       \\\n",
              "mean                                            0.090680        \n",
              "std                                             0.287244        \n",
              "min                                             0.000000        \n",
              "25%                                             0.000000        \n",
              "50%                                             0.000000        \n",
              "75%                                             0.000000        \n",
              "max                                             1.000000        \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:Accelerometer data   \n",
              "count                                        1588.000000       \\\n",
              "mean                                            0.000630        \n",
              "std                                             0.025094        \n",
              "min                                             0.000000        \n",
              "25%                                             0.000000        \n",
              "50%                                             0.000000        \n",
              "75%                                             0.000000        \n",
              "max                                             1.000000        \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:Acoustic signal return amplitude from the water body   \n",
              "count                                        1588.000000                                         \\\n",
              "mean                                            0.002519                                          \n",
              "std                                             0.050141                                          \n",
              "min                                             0.000000                                          \n",
              "25%                                             0.000000                                          \n",
              "50%                                             0.000000                                          \n",
              "75%                                             0.000000                                          \n",
              "max                                             1.000000                                          \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:Aluminium Bioaccumulation   \n",
              "count                                        1588.000000              \\\n",
              "mean                                            0.020151               \n",
              "std                                             0.140561               \n",
              "min                                             0.000000               \n",
              "25%                                             0.000000               \n",
              "50%                                             0.000000               \n",
              "75%                                             0.000000               \n",
              "max                                             1.000000               \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:Aluminium Dissolved Water Quality   \n",
              "count                                        1588.000000                      \\\n",
              "mean                                            0.010076                       \n",
              "std                                             0.099902                       \n",
              "min                                             0.000000                       \n",
              "25%                                             0.000000                       \n",
              "50%                                             0.000000                       \n",
              "75%                                             0.000000                       \n",
              "max                                             1.000000                       \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:Aluminium Total Water Quality   \n",
              "count                                        1588.000000                  \\\n",
              "mean                                            0.010705                   \n",
              "std                                             0.102943                   \n",
              "min                                             0.000000                   \n",
              "25%                                             0.000000                   \n",
              "50%                                             0.000000                   \n",
              "75%                                             0.000000                   \n",
              "max                                             1.000000                   \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:Ammonia-N Physicochemistry   \n",
              "count                                        1588.000000               \\\n",
              "mean                                            0.020151                \n",
              "std                                             0.140561                \n",
              "min                                             0.000000                \n",
              "25%                                             0.000000                \n",
              "50%                                             0.000000                \n",
              "75%                                             0.000000                \n",
              "max                                             1.000000                \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:Amplicon   \n",
              "count                                   1588.000000  \\\n",
              "mean                                       0.001889   \n",
              "std                                        0.043437   \n",
              "min                                        0.000000   \n",
              "25%                                        0.000000   \n",
              "50%                                        0.000000   \n",
              "75%                                        0.000000   \n",
              "max                                        1.000000   \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:Animal-borne video  ...   \n",
              "count                                        1588.000000       ...  \\\n",
              "mean                                            0.000630       ...   \n",
              "std                                             0.025094       ...   \n",
              "min                                             0.000000       ...   \n",
              "25%                                             0.000000       ...   \n",
              "50%                                             0.000000       ...   \n",
              "75%                                             0.000000       ...   \n",
              "max                                             1.000000       ...   \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:net_downward_shortwave_flux_in_air   \n",
              "count                                        1588.000000                       \\\n",
              "mean                                            0.001259                        \n",
              "std                                             0.035477                        \n",
              "min                                             0.000000                        \n",
              "25%                                             0.000000                        \n",
              "50%                                             0.000000                        \n",
              "75%                                             0.000000                        \n",
              "max                                             1.000000                        \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:pH   \n",
              "count                             1588.000000  \\\n",
              "mean                                 0.010076   \n",
              "std                                  0.099902   \n",
              "min                                  0.000000   \n",
              "25%                                  0.000000   \n",
              "50%                                  0.000000   \n",
              "75%                                  0.000000   \n",
              "max                                  1.000000   \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:pH (total scale) of the water body   \n",
              "count                                        1588.000000                       \\\n",
              "mean                                            0.006927                        \n",
              "std                                             0.082966                        \n",
              "min                                             0.000000                        \n",
              "25%                                             0.000000                        \n",
              "50%                                             0.000000                        \n",
              "75%                                             0.000000                        \n",
              "max                                             1.000000                        \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:particulate iron data quality flag   \n",
              "count                                        1588.000000                       \\\n",
              "mean                                            0.000630                        \n",
              "std                                             0.025094                        \n",
              "min                                             0.000000                        \n",
              "25%                                             0.000000                        \n",
              "50%                                             0.000000                        \n",
              "75%                                             0.000000                        \n",
              "max                                             1.000000                        \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:potential temperature   \n",
              "count                                        1588.000000          \\\n",
              "mean                                            0.000630           \n",
              "std                                             0.025094           \n",
              "min                                             0.000000           \n",
              "25%                                             0.000000           \n",
              "50%                                             0.000000           \n",
              "75%                                             0.000000           \n",
              "max                                             1.000000           \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:surface_albedo   \n",
              "count                                        1588.000000   \\\n",
              "mean                                            0.001259    \n",
              "std                                             0.035477    \n",
              "min                                             0.000000    \n",
              "25%                                             0.000000    \n",
              "50%                                             0.000000    \n",
              "75%                                             0.000000    \n",
              "max                                             1.000000    \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:the maximum potential quantum efficiency of Photosystem II   \n",
              "count                                        1588.000000                                               \\\n",
              "mean                                            0.000630                                                \n",
              "std                                             0.025094                                                \n",
              "min                                             0.000000                                                \n",
              "25%                                             0.000000                                                \n",
              "50%                                             0.000000                                                \n",
              "75%                                             0.000000                                                \n",
              "max                                             1.000000                                                \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:upwelling_longwave_flux_in_air   \n",
              "count                                        1588.000000                   \\\n",
              "mean                                            0.001259                    \n",
              "std                                             0.035477                    \n",
              "min                                             0.000000                    \n",
              "25%                                             0.000000                    \n",
              "50%                                             0.000000                    \n",
              "75%                                             0.000000                    \n",
              "max                                             1.000000                    \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:upwelling_shortwave_flux_in_air   \n",
              "count                                        1588.000000                    \\\n",
              "mean                                            0.001259                     \n",
              "std                                             0.035477                     \n",
              "min                                             0.000000                     \n",
              "25%                                             0.000000                     \n",
              "50%                                             0.000000                     \n",
              "75%                                             0.000000                     \n",
              "max                                             1.000000                     \n",
              "\n",
              "       AODN Discovery Parameter Vocabulary:voltage  \n",
              "count                                  1588.000000  \n",
              "mean                                      0.000630  \n",
              "std                                       0.025094  \n",
              "min                                       0.000000  \n",
              "25%                                       0.000000  \n",
              "50%                                       0.000000  \n",
              "75%                                       0.000000  \n",
              "max                                       1.000000  \n",
              "\n",
              "[8 rows x 393 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can check if there are any cell has value 1 in each row. This means the transform should be right and makes sure that item in Y has positive labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exist rows has no one values?:False\n"
          ]
        }
      ],
      "source": [
        "rows_with_ones = (Y_df == 1).any(axis=1)\n",
        "print(f'Exist rows has no one values?:{(~rows_with_ones).any()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save for further use\n",
        "save_to_file(Y_df, './output/keyword_target.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 5: Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ----------- \n",
            " Shape: (1588, 5) \n",
            " ColumnsIndex(['id', 'title', 'description', 'keywords', 'embedding'], dtype='object') \n",
            " ----------- \n"
          ]
        }
      ],
      "source": [
        "X_df = load_from_file('./output/keyword_train.pkl')\n",
        "\n",
        "def split_data(ds):\n",
        "    print(f' ----------- \\n Shape: {ds.shape} \\n Columns{ds.columns} \\n ----------- ')\n",
        "\n",
        "    X = np.array(ds['embedding'].tolist())\n",
        "    Y = load_from_file('./output/AODN_vocabs_label.pkl')\n",
        "    Y_labels = Y.columns.tolist()\n",
        "\n",
        "    Y = Y.to_numpy()\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)    \n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test, Y_labels\n",
        "\n",
        "X_train, Y_train, X_test, Y_test, Y_labels = split_data(X_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 6: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_time = datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "INPUT_DIM = 768\n",
        "N_LABELS = 393"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def keyword_model(X_train, Y_train, X_test, Y_test):\n",
        "    current_time = datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "    model = Sequential([\n",
        "        Input(shape=(INPUT_DIM,)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(N_LABELS, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    \n",
        "    # Adam(learning_rate=1e-3)\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision()])\n",
        "\n",
        "    epoch = 100\n",
        "    batch_size = 32\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, min_lr=1e-6)\n",
        "\n",
        "    history = model.fit(X_train, Y_train, epochs=epoch, batch_size=batch_size, validation_data=(X_test, Y_test), callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "    # history = model.fit(X_train, Y_train, epochs=epoch, batch_size=batch_size, class_weight=class_weights, validation_data=(X_test, Y_test))\n",
        "\n",
        "    model.save(f\"./output/saved/{current_time}-trained-keyword-epoch{epoch}-batch{batch_size}.keras\")\n",
        "\n",
        "    test_loss, test_accuracy, test_precision = model.evaluate(X_test, Y_test)\n",
        "    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}, Test Precision: {test_precision}\")\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0033 - loss: 0.4881 - precision: 0.0144 - val_accuracy: 0.0818 - val_loss: 0.0581 - val_precision: 0.6578 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1026 - loss: 0.0535 - precision: 0.4360 - val_accuracy: 0.0818 - val_loss: 0.0371 - val_precision: 0.7865 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0801 - loss: 0.0397 - precision: 0.5923 - val_accuracy: 0.0818 - val_loss: 0.0325 - val_precision: 0.7569 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1268 - loss: 0.0331 - precision: 0.7106 - val_accuracy: 0.0818 - val_loss: 0.0293 - val_precision: 0.8200 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1531 - loss: 0.0330 - precision: 0.7886 - val_accuracy: 0.1572 - val_loss: 0.0286 - val_precision: 0.8513 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1553 - loss: 0.0304 - precision: 0.8087 - val_accuracy: 0.1635 - val_loss: 0.0271 - val_precision: 0.8492 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1852 - loss: 0.0281 - precision: 0.8190 - val_accuracy: 0.4811 - val_loss: 0.0255 - val_precision: 0.8514 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2609 - loss: 0.0233 - precision: 0.8437 - val_accuracy: 0.4937 - val_loss: 0.0238 - val_precision: 0.9044 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2669 - loss: 0.0237 - precision: 0.8181 - val_accuracy: 0.5063 - val_loss: 0.0229 - val_precision: 0.8837 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2861 - loss: 0.0208 - precision: 0.8239 - val_accuracy: 0.4843 - val_loss: 0.0227 - val_precision: 0.8429 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2867 - loss: 0.0200 - precision: 0.8411 - val_accuracy: 0.5063 - val_loss: 0.0219 - val_precision: 0.8243 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3403 - loss: 0.0211 - precision: 0.8021 - val_accuracy: 0.5220 - val_loss: 0.0220 - val_precision: 0.8517 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3551 - loss: 0.0189 - precision: 0.8361 - val_accuracy: 0.5220 - val_loss: 0.0223 - val_precision: 0.8580 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3338 - loss: 0.0190 - precision: 0.8353 - val_accuracy: 0.5283 - val_loss: 0.0214 - val_precision: 0.8455 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3935 - loss: 0.0177 - precision: 0.8160 - val_accuracy: 0.5377 - val_loss: 0.0208 - val_precision: 0.8551 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3528 - loss: 0.0191 - precision: 0.8261 - val_accuracy: 0.5314 - val_loss: 0.0209 - val_precision: 0.8599 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3144 - loss: 0.0172 - precision: 0.8195 - val_accuracy: 0.5346 - val_loss: 0.0208 - val_precision: 0.8539 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3165 - loss: 0.0175 - precision: 0.8506 - val_accuracy: 0.5314 - val_loss: 0.0208 - val_precision: 0.8460 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3155 - loss: 0.0171 - precision: 0.8338 - val_accuracy: 0.5346 - val_loss: 0.0206 - val_precision: 0.8462 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3054 - loss: 0.0154 - precision: 0.8663 - val_accuracy: 0.5346 - val_loss: 0.0204 - val_precision: 0.8502 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2995 - loss: 0.0193 - precision: 0.8167 - val_accuracy: 0.5346 - val_loss: 0.0206 - val_precision: 0.8508 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3208 - loss: 0.0187 - precision: 0.8166 - val_accuracy: 0.5346 - val_loss: 0.0206 - val_precision: 0.8521 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3058 - loss: 0.0196 - precision: 0.8272 - val_accuracy: 0.5346 - val_loss: 0.0206 - val_precision: 0.8533 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3186 - loss: 0.0169 - precision: 0.8615 - val_accuracy: 0.5346 - val_loss: 0.0205 - val_precision: 0.8533 - learning_rate: 1.0000e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3404 - loss: 0.0156 - precision: 0.8599 - val_accuracy: 0.5346 - val_loss: 0.0205 - val_precision: 0.8533 - learning_rate: 1.0000e-05\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5626 - loss: 0.0207 - precision: 0.8699 \n",
            "Test Loss: 0.0204465351998806, Test Accuracy: 0.5345911979675293, Test Precision: 0.8502303957939148\n"
          ]
        }
      ],
      "source": [
        "model, history = keyword_model(X_train, Y_train, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 7: Predict on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
          ]
        }
      ],
      "source": [
        "confidence = 0.4\n",
        "predictions = model.predict(X_test)\n",
        "predicted_labels = (predictions > confidence).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 8: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluation(Y_test, predictions):\n",
        "    accuracy = accuracy_score(Y_test, predictions)\n",
        "    hammingloss = hamming_loss(Y_test, predictions)\n",
        "    precision = precision_score(Y_test, predictions, average='micro')\n",
        "    recall = recall_score(Y_test, predictions, average='micro')\n",
        "    f1 = f1_score(Y_test, predictions, average='micro')\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'hammingloss': hammingloss,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'accuracy': 0.5566037735849056, 'hammingloss': 0.006121273224830765, 'precision': 0.8267543859649122, 'recall': 0.5540044085231447, 'f1': 0.6634403871535416}\n"
          ]
        }
      ],
      "source": [
        "eval_trained_model = evaluation(Y_test=Y_test, predictions=predicted_labels)\n",
        "print(eval_trained_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Labels: ['AODN Discovery Parameter Vocabulary:Fluorescence of the water body', 'AODN Discovery Parameter Vocabulary:Practical salinity of the water body', 'AODN Discovery Parameter Vocabulary:Temperature of the water body', 'AODN Discovery Parameter Vocabulary:Turbidity of the water body']\n",
            "True Labels: ['AODN Discovery Parameter Vocabulary:Fluorescence of the water body', 'AODN Discovery Parameter Vocabulary:Practical salinity of the water body', 'AODN Discovery Parameter Vocabulary:Temperature of the water body', 'AODN Discovery Parameter Vocabulary:Turbidity of the water body']\n",
            "----------------------\n",
            "Predicted Labels: ['AODN Discovery Parameter Vocabulary:Abundance of biota']\n",
            "True Labels: ['AODN Discovery Parameter Vocabulary:Abundance of biota']\n",
            "----------------------\n",
            "Predicted Labels: ['AODN Discovery Parameter Vocabulary:Abundance of biota']\n",
            "True Labels: ['AODN Discovery Parameter Vocabulary:Abundance of biota', 'AODN Discovery Parameter Vocabulary:Biotic taxonomic identification']\n",
            "----------------------\n",
            "Predicted Labels: ['AODN Discovery Parameter Vocabulary:Fluorescence of the water body', 'AODN Discovery Parameter Vocabulary:Practical salinity of the water body', 'AODN Discovery Parameter Vocabulary:Temperature of the water body', 'AODN Discovery Parameter Vocabulary:Turbidity of the water body']\n",
            "True Labels: ['AODN Discovery Parameter Vocabulary:Fluorescence of the water body', 'AODN Discovery Parameter Vocabulary:Practical salinity of the water body', 'AODN Discovery Parameter Vocabulary:Temperature of the water body', 'AODN Discovery Parameter Vocabulary:Turbidity of the water body']\n",
            "----------------------\n",
            "Predicted Labels: ['AODN Discovery Parameter Vocabulary:Fluorescence of the water body', 'AODN Discovery Parameter Vocabulary:Practical salinity of the water body', 'AODN Discovery Parameter Vocabulary:Temperature of the water body', 'AODN Discovery Parameter Vocabulary:Turbidity of the water body']\n",
            "True Labels: ['AODN Discovery Parameter Vocabulary:Fluorescence of the water body', 'AODN Discovery Parameter Vocabulary:Practical salinity of the water body', 'AODN Discovery Parameter Vocabulary:Temperature of the water body', 'AODN Discovery Parameter Vocabulary:Turbidity of the water body']\n",
            "----------------------\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    predicted_keywords = [Y_labels[j] for j in range(len(predicted_labels[i])) if predicted_labels[i][j] == 1]\n",
        "    true_keywords = [Y_labels[j] for j in range(len(Y_test[i])) if Y_test[i][j] == 1]\n",
        "\n",
        "    print(f\"Predicted Labels: {predicted_keywords}\")\n",
        "    print(f\"True Labels: {true_keywords}\")\n",
        "    print(\"----------------------\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
