{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML model for Keyword Classification\n",
    "This notebook introduces (1) how we explore, prepare and preprocess the datasets; (2) how we train and evaluate the ML model; and (3) how we use this trained ML model.\n",
    "## Problem Description\n",
    "In the catalogue $C = \\{M, K, P\\}$, a subset of metadata records, $M_t \\subseteq M$, have not yet been categorised with keywords. For these records, $K_i = \\emptyset $ for all $m_i \\in M_t$. Given another subset of metadata records, $M_s \\subseteq M$, where each record has already been categorised with keywords (i.e., $K_i \\neq \\emptyset $ for all $m_i \\in M_s$). The research question is as follows:\n",
    "\n",
    "How to design and develop a machine learning model, denoted as $MM_{keywords}$, that can automatically label the uncategorised metadata records $M_t$ using a predefined set of keywords $K$. Specifically, the model should be trained to learn a mapping rule $d_i \\mapsto K_i$ based on the observed patterns from the labelled metadata records $M_s$, where each description $d_i$ of a metadata record $m_i \\in M_s$ is associated with a set of keywords $K_i$. Once trained, the model should be able to apply this learned mapping to accurately categorise the records in $M_t$ by assigning their corresponding keywords based on the records' descriptions.\n",
    "\n",
    "To simplify the task, we restrict the scope of keywords to those falling within the primary AODN vocabulary:\n",
    "- AODN Discovery Parameter Vocabulary\n",
    "\n",
    "Only keywords $k_j \\in K_i$ that are part of the listed AODN vocabularies will be considered. Any keyword not belonging to these vocabularies will be excluded from $K_i$ for all metadata records in the categorised metadata set $M_s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Sample Set $M_s$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.preprocessor as preprocessor\n",
    "sampleDS = preprocessor.load_sample()\n",
    "sampleDS.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keywords $K_i$ of a metadata record $M_i$ is in JSON format, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDS.loc[0]['keywords']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "We preprocessed the keywords field for better readability, converting the JSON format to a list of keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDS = preprocessor.extract_labels(sampleDS)\n",
    "sampleDS.loc[0]['keywords']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean samples, i.e., remove records have empty keyword. (see example [4673208b-def5-4340-9818-8419496e4863](https://geonetwork-edge.edge.aodn.org.au/geonetwork/srv/eng/catalog.search#/metadata/4673208b-def5-4340-9818-8419496e4863), [f55a53db-09fc-480d-aa9e-2aa6bb304b8c](f55a53db-09fc-480d-aa9e-2aa6bb304b8c), and [d265307c-5a6a-4a52-b352-35ad904fca52](https://geonetwork-edge.edge.aodn.org.au/geonetwork/srv/eng/catalog.search#/metadata/d265307c-5a6a-4a52-b352-35ad904fca52))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_lengths = sampleDS['keywords'].apply(len)\n",
    "empty_keywords_records_index= list_lengths[list_lengths == 0].index.tolist()\n",
    "print(f'Index of records has empty keywords field: {empty_keywords_records_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_keywords_records = []\n",
    "for index in empty_keywords_records_index:\n",
    "    empty_keywords_records.append(sampleDS.iloc[index]['id'])\n",
    "empty_keywords_records\n",
    "sampleDS_cleaned = sampleDS[~sampleDS['id'].isin(empty_keywords_records)]\n",
    "sampleDS_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the embeddings of metadata records as the input (feature) $X$, and we use the keywords (labels) as the output $Y$. So we convert the labels to math representations: a binary matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = preprocessor.prepare_Y_matrix(sampleDS_cleaned)\n",
    "labels = Y.columns\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Distribution\n",
    "By plotting the label distribution, we can have a deeper understanding of the sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "category_distribution = Y.copy()\n",
    "category_distribution = category_distribution.sum()\n",
    "\n",
    "category_distribution.sort_values()\n",
    "\n",
    "# plt.figure(figsize=(15,60))\n",
    "# category_distribution.sort_values().plot(kind='barh', color='skyblue', edgecolor='black')\n",
    "# plt.title(\"Keywords Distribution\")\n",
    "# plt.ylabel(\"Keywords\")\n",
    "# plt.xlabel(\"Count of Related Metadata Records\")\n",
    "# plt.xticks(fontsize=12)\n",
    "# plt.yticks(fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_K = Y.copy()\n",
    "count_K['Label Count'] = Y.sum(axis=1)\n",
    "\n",
    "print(f\"Average number of labels each record has: {count_K['Label Count'].mean()}\")\n",
    "print(f\"Maximum number of labels a record has: {count_K['Label Count'].max()}\")\n",
    "print(f\"Minium number of labels a record has: {count_K['Label Count'].min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these statistical analysis, we identified several key challenges in this multi-label classification task:\n",
    "\n",
    "- **Global Label Imbalance**: The keyword distribution is highly imbalanced. For example, the keyword 'Temperature of the water body' appears in over 1,000 records, while 118 keywords appear only once. This imbalance causes the model to favor predicting common keywords like 'Temperature of the water body' over rare keywords, leading to biased and less accurate predictions for minority classes.\n",
    "\n",
    "- **Internal Label Imbalance**: On average, each record is associated with 4.14 keywords. This means averagely, each record has 4.14 positive labels (keywords present) and the rest are negative labels (keywords absent). As a result, the model tends to predict negative labels more frequently, making it biased towards predicting the absence of keywords.\n",
    "\n",
    "To improve the label distribution issue, we first oversample rare classes, that is the labels only appear once or twice in the overall sample recrods.\n",
    "### First Round Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify rare lables\n",
    "category_distribution.sort_values()\n",
    "category_distribution_df = category_distribution.to_frame(name='count')\n",
    "rare_category = category_distribution_df[category_distribution_df['count']==1] + category_distribution_df[category_distribution_df['count']==2]\n",
    "print(f'Number of labels which has rare records: {len(rare_category)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.preprocessor import resampling\n",
    "\n",
    "X = np.array(sampleDS_cleaned['embedding'].tolist())\n",
    "X_oversampled, Y_oversampled = resampling(X_train=X, Y_train=Y.to_numpy(), strategy='ROS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can check the label distribution for the oversampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "K_oversampled = pd.DataFrame(Y_oversampled, columns=labels)\n",
    "\n",
    "category_distribution = K_oversampled.copy()\n",
    "category_distribution = category_distribution.sum()\n",
    "\n",
    "category_distribution.sort_values()\n",
    "category_distribution_df = category_distribution.to_frame(name='count')\n",
    "rare_category = category_distribution_df[category_distribution_df['count']==1] + category_distribution_df[category_distribution_df['count']==2]\n",
    "print(f'Number of labels which has rare records: {len(rare_category)}')\n",
    "\n",
    "category_distribution_df['count'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, records with rare labels are duplicated to increase their frequency. After oversampling, we found that the minimum value is 539, meaning each label appears in at least 539 records. In this way, we tried to balance the label imbalance distribution issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train and Test Sets\n",
    "We select description embedding as input X, and keyword vetors as output Y. We split the train and test sets follow the propotion of 80%-20%. Notably, we don't split validation set in this step, as in our model, we seperate the validation set when fit the model by setting parameter `validation_split=0.1`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessor import prepare_train_validation_test\n",
    "\n",
    "dimension, n_labels, X_train, Y_train, X_test, Y_test = prepare_train_validation_test(X_oversampled, Y_oversampled)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling for minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled, Y_train_resampled = resampling(X_train=X_train, Y_train=Y_train, strategy='SMOTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model.keywordModel as km\n",
    "label_weight_dict = {}\n",
    "model, history = km.keyword_model(X_train, Y_train, X_test, Y_test, label_weight_dict, dimension, n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.keywordModel import evaluation, prediction\n",
    "\n",
    "confidence = 0.5\n",
    "predicted_labels = prediction(X_test, model, confidence)\n",
    "eval = evaluation(Y_test=Y_test, predictions=predicted_labels)\n",
    "print(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load target set $M_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessor import load_target\n",
    "targetDS = load_target()\n",
    "targetDS.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.keywordModel import prediction\n",
    "target_X = np.array(targetDS['embedding'].tolist())\n",
    "target_predicted_labels = prediction(target_X, model, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.keywordModel import get_predicted_keywords\n",
    "get_predicted_keywords(target_predicted_labels, labels, targetDS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
